{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential example.\n",
    "\n",
    "In this notebook, we demonstrate the calculation of error bounds for the Swiss Army infinitesimal jackknife for a simple scalar exponential family model.  Although the model is trivial, it simplicity aids understanding the interplay of different elements of Theorem 1.\n",
    "\n",
    "In this notebook, we pay particular attention to the influence of the choice of $\\Omega_\\theta$ on the resulting bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import scipy as sp\n",
    "import paragami\n",
    "import vittles\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A convenience function to visually compare two variables.\n",
    "def comparison_plot(x, y):\n",
    "    plt.plot(x, x, 'k')\n",
    "    plt.plot(x, y, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, draw some data from an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.00887384667998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_data(num_obs, theta_true):\n",
    "    return np.random.exponential(np.exp(-1 * theta_true), num_obs)\n",
    "\n",
    "num_obs = 10000\n",
    "theta_true = np.log(0.1)\n",
    "\n",
    "x = generate_data(num_obs, theta_true)\n",
    "\n",
    "plt.hist(x, 100);\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we specify the weighted MLE loss function.  In this case, the optimum is available in closed form.  For convenience we implement the closed form optimum and test that it matches the optimum of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: f = 3.30362589\n",
      "Iter 1: f = 3.30362524\n",
      "Iter 2: f = 3.30362524\n",
      "Iter 3: f = 3.30362524\n",
      "Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": [
    "def get_opt(w, x):\n",
    "    return np.log(np.sum(w)) - np.log(np.sum(w * x))\n",
    "\n",
    "def eval_log_loss(theta, w, x):\n",
    "    ll = -1 * np.sum(w * (-1 * x * np.exp(theta) + theta)) / num_obs\n",
    "    return ll\n",
    "\n",
    "w = np.ones(num_obs) + 0.1 * (np.random.random(num_obs) - 0.5)\n",
    "\n",
    "# Test the loss function and optimum with random weights.\n",
    "log_loss_objective = paragami.OptimizationObjective(\n",
    "    lambda theta: eval_log_loss(theta, w, x))\n",
    "log_loss_objective.reset()\n",
    "log_loss_objective.set_log_every(1)\n",
    "opt = sp.optimize.minimize(\n",
    "    fun=log_loss_objective.f,\n",
    "    jac=log_loss_objective.grad,\n",
    "    method='bfgs',\n",
    "    x0=theta_true,\n",
    "    options={'gtol': 1e-12})\n",
    "print(opt.message)\n",
    "\n",
    "assert(np.abs(opt.x[0] - get_opt(w, x)) < 1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimum at the original weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = np.ones(num_obs)\n",
    "theta_opt = get_opt(w1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an IJ predictor object using ``vittles``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ij_predictor = \\\n",
    "    vittles.HyperparameterSensitivityLinearApproximation(\n",
    "        lambda theta, w: eval_log_loss(theta, w, x),\n",
    "        opt_par_value=np.array([theta_opt]),\n",
    "        hyper_par_value=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the IJ predictions and exact CV for a range of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_loo = np.ones(num_obs)\n",
    "\n",
    "theta_ij = np.full(num_obs, float('nan'))\n",
    "theta_cv = np.full(num_obs, float('nan'))\n",
    "for n in range(num_obs):\n",
    "    w_loo[n] = 0\n",
    "    theta_ij[n] = ij_predictor.predict_opt_par_from_hyper_par(w_loo)\n",
    "    theta_cv[n] = get_opt(w_loo, x)\n",
    "    w_loo[n] = 1\n",
    "\n",
    "comparison_plot(theta_cv - theta_opt, theta_ij - theta_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error bound calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate error bounds for the IJ approximation.\n",
    "\n",
    "For this model, we will parameterize the log likelihood of datapoint $x_n$ as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell\\left(x_{n},\\theta\\right)\t=& -\\exp(\\theta) x_{n} + \\theta \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "By allowing $\\theta$ to take values in all of $\\mathbb{R}$, we simplify some calculation and avoid large derivatives at the boundary of the valid domain.\n",
    "\n",
    "For convenience, we define\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "M\\left(w\\right)\t=& \\frac{1}{N}\\sum_{n=1}^{N}w_{n}x_{n}\\\\\n",
    "S\\left(w\\right)\t=& \\frac{1}{N}\\sum_{n=1}^{N}w_{n}x_{n}^{2}\\\\\n",
    "\\bar{w}\t=& \\frac{1}{N}\\sum_{n=1}^{N}w_{n}.\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Given these definitions,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g_{n}\\left(\\theta\\right)&=-\\exp\\left(\\theta\\right)x_{n}+1\\\\\n",
    "h_{n}\\left(\\theta\\right)&=-\\exp\\left(\\theta\\right)x_{n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and the aggregated quantities are\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L\\left(\\theta,w\\right) &= -M\\left(w\\right)\\exp\\left(\\theta\\right)+\\bar{w}\\theta\\\\\n",
    "G\\left(\\theta,w\\right) &= -M\\left(w\\right)\\exp\\left(\\theta\\right)+\\bar{w}\\\\\n",
    "H\\left(\\theta,w\\right) &= -M\\left(w\\right)\\exp\\left(\\theta\\right).\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that\n",
    "\n",
    "$$\n",
    "\\exp\\left(\\hat{\\theta}\\right)=\\frac{1}{M(w_1)}.\n",
    "$$\n",
    "\n",
    "Define $w_1 = (1, ...., 1)^T$ to be the vector of unity weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define the domain as $\\Omega_{\\theta}=\\left(\\theta_{min}, \\theta_{max}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 1.\n",
    "\n",
    "In this case, the objective is continuous and infinitely differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 2.\n",
    "\n",
    "By direct calculation,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "|H\\left(\\theta, w_1\\right)|^{-1}\t&= \\frac{1}{\\exp\\left(\\theta\\right) M(w_1)} \n",
    "    \\le \\frac{1}{\\exp\\left(\\theta_{min}\\right) M(w_1)}\\Rightarrow \\\\\n",
    "C_{op}&:= \\frac{1}{\\exp\\left(\\theta_{min}\\right) M(w_1)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 3.\n",
    "\n",
    "We will bound Condition 1 directly without using Corollary 1, so the constants $C_g$ and $C_h$ are not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 4.\n",
    "\n",
    "To calculate $L_h$, we need to choose a window $\\Delta_\\theta$ and upper bound the following quantity:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sup_{\\theta\\in\\left(\\hat{\\theta}-\\Delta_{\\theta},\\hat{\\theta}+\\Delta_{\\theta}\\right)}\n",
    "    \\frac{\\frac{1}{N} \\left\\Vert h\\left(\\theta\\right)-h\\left(\\hat{\\theta}\\right) \\right\\Vert_{2}^{2}}\n",
    "    {\\left\\Vert \\theta-\\hat{\\theta} \\right\\Vert_{2}^{2}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "By convexity of $\\left(\\exp\\left(\\theta\\right)-\\exp\\left(\\hat{\\theta}\\right)\\right)^{2}$, we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sup_{\\theta\\in\\left(\\hat{\\theta}-\\Delta_{\\theta},\\hat{\\theta}+\\Delta_{\\theta}\\right)}\n",
    "    \\frac{\\frac{1}{N}\\left\\Vert h\\left(\\theta\\right) - h\\left(\\hat{\\theta}\\right) \\right\\Vert_{2}^{2}}\n",
    "         {\\left\\Vert \\theta-\\hat{\\theta} \\right\\Vert_{2}^{2}}     \n",
    " =& \\sup_{\\theta\\in\\left(\\hat{\\theta}-\\Delta_{\\theta},\\hat{\\theta}+\\Delta_{\\theta}\\right)}\n",
    "    \\frac{\\frac{1}{N} \\sum_{n=1}^N \\left( h_n(\\theta) - h_n(\\hat\\theta)\\right)^2}\n",
    "         {\\left\\Vert \\theta-\\hat{\\theta} \\right\\Vert_{2}^{2}}\t\\\\\n",
    " =& \\sup_{\\theta\\in\\left(\\hat{\\theta}-\\Delta_{\\theta},\\hat{\\theta}+\\Delta_{\\theta}\\right)}\n",
    "    \\frac{\\frac{1}{N} \\sum_{n=1}^N x_n^2 \\left( \\exp(\\theta) - \\exp(\\hat\\theta)\\right)^2}\n",
    "         {\\left\\Vert \\theta-\\hat{\\theta} \\right\\Vert_{2}^{2}}\t\\\\\n",
    " =& S(w_1)   \\sup_{\\theta\\in\\left(\\hat{\\theta}-\\Delta_{\\theta},\\hat{\\theta}+\\Delta_{\\theta}\\right)}\n",
    "    \\frac{\\left(\\exp\\left(\\theta\\right)-\\exp\\left(\\hat{\\theta}\\right)\\right)^{2}}{\\left\\Vert{\\theta-\\hat{\\theta}}\\right\\Vert_{2}^{2}} \\\\\n",
    "=& S(w_1) \\frac{\\left(\\exp\\left(\\hat{\\theta}+\\Delta_{\\theta}\\right)-\\exp\\left(\\hat{\\theta}\\right)\\right)^{2}}{\\Delta_{\\theta}^{2}} \\\\\n",
    "=& S(w_1) \\frac{\\exp\\left(2\\hat{\\theta}\\right)\\left(\\exp\\left(\\Delta_{\\theta}\\right)-1\\right)^{2}}{\\Delta_{\\theta}^{2}}\n",
    "\t\\\\\n",
    "=& \\frac{S(w_1) }{M(w_1)^{2}}\\frac{\\left(\\exp\\left(\\Delta_{\\theta}\\right)-1\\right)^{2}}{\\Delta_{\\theta}^{2}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So we can take\n",
    "\n",
    "$$\n",
    "L_{h}\t=\\frac{\\sqrt{S(w_1)}}{M(w_1)}\\frac{\\left|\\exp\\left(\\Delta_{\\theta}\\right)-1\\right|}{\\Delta_{\\theta}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 5.\n",
    "\n",
    "Because we are doing leave-one-out, $\\sum_{n=1}^N (w_n - 1) = 1$ for all weight vectors, and\n",
    "\n",
    "$$\n",
    "C_{w}\t=\\sqrt{\\frac{1}{N}\\sum_{n=1}^{N}\\left(w_{n}-1\\right)^{2}}\n",
    "\t=\\frac{1}{\\sqrt{N}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The constant $C_{IJ}$.\n",
    "\n",
    "Here, the dimension $D=1$. Combining the above results,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "C_{IJ}\t=& 1+DC_{w}L_{h}C_{op} \\\\\n",
    "=& 1+1\\cdot\\frac{1}{\\sqrt{N}}\\frac{\\sqrt{S(w_1)}}{M(w_1)}\\frac{\\left|\\exp\\left(\\Delta_{\\theta}\\right)-1\\right|}{\\Delta_{\\theta}}\\frac{\\exp\\left(-\\theta_{min}\\right)}{M(w_1)} \\\\\n",
    "=& 1+\\frac{\\sqrt{S(w_1)}}{\\sqrt{N}M(w_1)^2}\n",
    "    \\frac{\\left|\\exp\\left(\\Delta_{\\theta}\\right)-1\\right|}{\\Delta_{\\theta}}\\exp\\left(-\\theta_{min}\\right)\\\\\n",
    "\\approx& 1+\\frac{\\sqrt{S(w_1)}}{\\sqrt{N}M(w_1)^2}\\left(1+\\frac{1}{2}\\Delta_{\\theta}\\right)\\exp\\left(-\\theta_{min}\\right),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the final approximation holds for small $\\Delta_\\theta$ by a Taylor series approximation to $\\exp(\\Delta_\\theta)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition 1.\n",
    "\n",
    "Define\n",
    "\n",
    "$$\n",
    "x^* = \\max_{n \\in [N]} x_n.\n",
    "$$\n",
    "\n",
    "For leave one out, a gradient complexity bound is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sup_{w\\in W}\\sup_{\\theta\\in\\Omega_{\\theta}}\n",
    "    \\left| \\frac{1}{N} \\sum_{n=1}^{N}\\left(w_{n}-1\\right)g_{n}\\left(\\theta\\right) \\right| &\\le    \n",
    "\\frac{1}{N}\\sup_{\\theta\\in\\Omega_{\\theta}}\\left\\Vert{g\\left(\\theta\\right)}\\right\\Vert_{\\infty} \\\\\n",
    "&=\\frac{1}{N}\\sup_{\\theta\\in\\Omega_{\\theta}} \\max_{n\\in\\left[N\\right]}\n",
    "    \\left|g_{n}\\left(\\theta\\right)\\right| \\\\\n",
    "&=\\frac{1}{N}\\sup_{\\theta\\in\\Omega_{\\theta}}\\max_{n\\in\\left[N\\right]}\n",
    "    \\left|\\exp\\left(\\theta\\right)x_{n} - 1\\right| \\\\\n",
    "&\\le\\frac{1}{N}\\sup_{\\theta\\in\\Omega_{\\theta}}\\max_{n\\in\\left[N\\right]}\n",
    "    \\left(\\exp\\left(\\theta\\right) x_{n} + 1\\right) \\\\\n",
    "&=\\frac{1}{N}\\left(\n",
    "    \\left( \\sup_{\\theta\\in\\Omega_{\\theta}} \\exp\\left(\\theta\\right) \\right)\n",
    "    \\left(\\max_{n\\in\\left[N\\right]} x_{n} \\right) + 1\n",
    "    \\right) \\\\\n",
    "&=\\frac{1}{N}\\left( \\exp\\left(\\theta_{max}\\right)x^{*} + 1 \\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Similarly, a Hessian complexity bound is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sup_{w\\in W}\\sup_{\\theta\\in\\Omega_{\\theta}}\n",
    "    \\left|\\frac{1}{N}\\sum_{n=1}^{N}\\left(w_{n}-1\\right)h_{n}\\left(\\theta\\right)\\right|\t\\le &\n",
    "\\frac{1}{N}\\sup_{\\theta\\in\\Omega_{\\theta}}\\max_{n\\in\\left[N\\right]}\n",
    "    \\left|\\exp\\left(\\theta\\right)x_{n}\\right| \\\\\n",
    "\\le& \\frac{1}{N}\\exp\\left(\\theta_{max}\\right)x^{*}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The gradient bound is always looser than the Hessian bound.  Consequently we can satisfy Condition 1 with\n",
    "\n",
    "$$\n",
    "\\delta\t=\\frac{1}{N}\\left(\\exp\\left(\\theta_{max}\\right)x^{*}+1\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing $\\Delta_\\theta$.\n",
    "\n",
    "In order to apply Theorem 1, we will require\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\delta\t\\le& \\Delta_{\\theta}C_{op}^{-1}\\\\ \n",
    "=& \\Delta_{\\theta}M(w_1)\\exp\\left(\\theta_{min}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\delta\t\\le& \\frac{1}{2}C_{IJ}^{-1}C_{op}^{-1} \\\\\n",
    "=& \\frac{1}{2}\\left(1+\\frac{\\sqrt{S(w_1)}}{\\sqrt{N}M(w_1)^2}\\frac{\\left|\\exp\\left(\\Delta_{\\theta}\\right)-1\\right|}{\\Delta_{\\theta}}\\exp\\left(-\\theta_{min}\\right)\\right)M(w_1)\\exp\\left(\\theta_{min}\\right) \\\\\n",
    "=& \\frac{1}{2}\\left(M(w_1)\\exp\\left(\\theta_{min}\\right) +\n",
    "    \\sqrt{\\frac{S(w_1)}{N}}\\frac{1}{M(w_1)}\\frac{\\left|\\exp\\left(\\Delta_{\\theta}\\right)-1\\right|}{\\Delta_{\\theta}}\\right) \\\\\n",
    "\\approx& \\frac{1}{2}\\left(M(w_1)\\exp\\left(\\theta_{min}\\right)+\\sqrt{\\frac{S(w_1)}{N}}\\frac{1}{M(w_1)}\\left(1+\\Delta_{\\theta}\\right)\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The complexity bound $\\delta$ is set by quantities that don't depend on $\\Delta_\\theta$, and both bounds are unboundedly increasing in $\\Delta_\\theta$, so we can always find a $\\Delta_\\theta$ large enough for Theorem 1 to apply.\n",
    "\n",
    "We expect $\\Delta_\\theta < \\frac{1}{2}$, in which case satisfying the first bound automatically satisfies the second.  Consequently, for simplicity we choose\n",
    "\n",
    "$$\n",
    "\\Delta_\\theta = \\delta C_{op}\n",
    "$$\n",
    "\n",
    "and check that the second bound is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement a function to calculate these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ij_error_bounds(theta_min, theta_max, x):\n",
    "    ij_error_terms = dict()\n",
    "    \n",
    "    # The objective is determined by these sufficient statistics.\n",
    "    m1 = np.sum(x) / num_obs\n",
    "    s1 = np.sum(x ** 2) / num_obs\n",
    "    x_star = np.max(x)\n",
    "\n",
    "    c_g = np.sqrt(np.exp(2 * theta_max) * s1 + 2 * np.exp(theta_max) * m1 + 1)\n",
    "    c_h = np.sqrt(np.exp(theta_max) * s1)\n",
    "    c_op = np.exp(-1 * theta_min) / m1\n",
    "    c_w = 1 / np.sqrt(num_obs)\n",
    "    d = 1\n",
    "\n",
    "    delta = (np.exp(theta_max) * x_star + 1) / num_obs\n",
    "\n",
    "    delta_theta = delta * c_op + 1e-3\n",
    "    l_h = (np.sqrt(s1) / m1) * np.abs(np.exp(delta_theta) - 1) / delta_theta\n",
    "\n",
    "    # This should be true by construction.\n",
    "    assert delta <= delta_theta / c_op\n",
    "\n",
    "    c_ij = 1 + d * c_w * l_h * c_op\n",
    "    \n",
    "    # This we have to check.\n",
    "    if not delta <=  0.5 / (c_ij * c_op):\n",
    "        err_msg = (\n",
    "            'The IJ bound is invalid -- probably \\\\Omega_\\\\theta is too large.  ' +\n",
    "            '\\n\\nThe bound could be made valid by numerically solving the nonlinear ' +\n",
    "            'equation to find an appropriate \\\\Delta_\\\\theta, but the resulting bound ' +\n",
    "            'would probably be unusably loose.')\n",
    "        raise ValueError(err_msg)\n",
    "\n",
    "    err_bound = 2 * (c_op ** 2) * c_ij * (delta ** 2)\n",
    "    \n",
    "    ij_error_terms['theta_min'] = theta_min\n",
    "    ij_error_terms['theta_max'] = theta_max\n",
    "    ij_error_terms['c_g'] = c_g\n",
    "    ij_error_terms['c_h'] = c_h\n",
    "    ij_error_terms['c_op'] = c_op\n",
    "    ij_error_terms['c_w'] = c_w\n",
    "    ij_error_terms['d'] = d\n",
    "    ij_error_terms['delta'] = delta\n",
    "    ij_error_terms['delta_theta'] = delta_theta\n",
    "    ij_error_terms['l_h'] = l_h\n",
    "    ij_error_terms['c_ij'] = c_ij\n",
    "    ij_error_terms['err_bound'] = err_bound\n",
    "\n",
    "    return ij_error_terms\n",
    "\n",
    "\n",
    "def print_error_bounds(ij_error_terms):\n",
    "    for k, v in ij_error_terms.items():\n",
    "        print('{:>15} = {}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take an initial guess at $\\Omega_\\theta$ based on the asymptotic variance.  We will check and refine this guess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta standard deviation:  0.009999999999999992\n",
      "              d = 1\n",
      "            c_w = 0.01\n",
      "    delta_theta = 0.002001847745624872\n",
      "      theta_min = -2.3234720841690373\n",
      "           c_ij = 1.0143914341923759\n",
      "            c_h = 4.503176515483211\n",
      "            c_g = 2.25995438528836\n",
      "           c_op = 1.0202013400267547\n",
      "      err_bound = 2.0362871443197175e-06\n",
      "      theta_max = -2.2834720841690372\n",
      "          delta = 0.0009820098311168644\n",
      "            l_h = 1.4106464702348336\n"
     ]
    }
   ],
   "source": [
    "h1 = num_obs * autograd.hessian(lambda theta: eval_log_loss(theta, w1, x))(theta_opt)\n",
    "theta_sd = np.sqrt(1 / h1)\n",
    "print('theta standard deviation: ', theta_sd)\n",
    "\n",
    "theta_min = theta_opt - 2 * theta_sd\n",
    "theta_max = theta_opt + 2 * theta_sd\n",
    "\n",
    "ij_error_terms = get_ij_error_bounds(theta_min, theta_max, x)\n",
    "print_error_bounds(ij_error_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check that the bounds capture the true error and that $\\hat\\theta(w)$ is entirely contained in $\\Omega_\\theta$.  Let $\\epsilon$  denote the error bound.  Note that the latter condition can be checked _without calculating $\\hat\\theta(w)$_ using the fact that, by the triangle inequality,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "|\\hat\\theta(w) - \\hat\\theta)| <& |\\hat\\theta_{IJ}(w) - \\hat\\theta)| + \\epsilon.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If the quantities on the right hand side are all contained in $\\Omega_\\theta$, then so is $\\hat\\theta(\\tilde{w})$ for all $\\tilde{w}$ such that $\\left\\Vert \\tilde{w} - 1 \\right\\Vert_2 \\le \\left\\Vert w - w_1 \\right\\Vert_2$.  This is all that is needed of $\\Omega_\\theta$ in Theorem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omega sufficient:\t True\n",
      "Error bound sufficient:\t True\n",
      "Max error bound ratio:\t 0.1811798091321689\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_error_bound(theta_ij, theta_cv, ij_error_terms, plot=False):\n",
    "    err_bound = ij_error_terms['err_bound']\n",
    "    \n",
    "    omega_sufficient = np.all(np.logical_and(\n",
    "              theta_ij <= ij_error_terms['theta_max'],\n",
    "              theta_ij >= ij_error_terms['theta_min']))\n",
    "    print('Omega sufficient:\\t', omega_sufficient)\n",
    "    \n",
    "    err = theta_cv - theta_ij\n",
    "    bound_sufficient = np.all(np.abs(err) < err_bound)\n",
    "    print('Error bound sufficient:\\t', bound_sufficient)\n",
    "    print('Max error bound ratio:\\t', np.max(np.abs(err) / err_bound))\n",
    "    \n",
    "    if plot:\n",
    "        plt.hist(err / err_bound);\n",
    "        plt.title('Ratio of error to uniform bound');\n",
    "    \n",
    "    return bound_sufficient and omega_sufficient\n",
    "\n",
    "assert check_error_bound(theta_ij, theta_cv, ij_error_terms, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimially choosing the size of $\\Omega_\\theta$.\n",
    "\n",
    "As is clear from the above discussion and the definition of the function ``get_ij_error_bounds``, we have a map from the bounds $(\\theta_{min}, \\theta_{max}) \\mapsto \\epsilon$, where $|\\hat\\theta_{IJ}(w) - \\hat\\theta(w)| < \\epsilon$.  Tigher bounds on $\\theta$ lead to a smaller $\\epsilon$.   If we find that the original choice of $\\Omega_\\theta$ is larger than necessary, we can reduce its size, potentially decreasing the error bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can potentially decrease the size of \\Omega_\\theta.\n",
    "def get_implied_omega_theta(theta_ij, ij_error_terms):\n",
    "    err_bound = ij_error_terms['err_bound']\n",
    "    pred_theta_max = np.max(theta_ij) + err_bound\n",
    "    pred_theta_min = np.min(theta_ij) - err_bound\n",
    "    return (pred_theta_min, pred_theta_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Omega_theta:\t(-2.3234720841690373, -2.2834720841690372)\n",
      "\n",
      "\n",
      "Implied Omega_theta:\t(-2.3234720841690373, -2.2834720841690372)\n",
      "Bound change: 0.03913138290025664\n",
      "Results for new bounds:\n",
      "Omega sufficient:\t True\n",
      "Error bound sufficient:\t True\n",
      "Max error bound ratio:\t 0.19521106622236165\n",
      "\n",
      "\n",
      "Implied Omega_theta:\t(-2.303574120115332, -2.3027055030155887)\n",
      "Bound change: 0.0\n",
      "Results for new bounds:\n",
      "Omega sufficient:\t True\n",
      "Error bound sufficient:\t True\n",
      "Max error bound ratio:\t 0.19521106622236165\n"
     ]
    }
   ],
   "source": [
    "bound_change = float('inf')\n",
    "tol = 1e-4\n",
    "pred_theta_min = theta_min\n",
    "pred_theta_max = theta_max\n",
    "print('Original Omega_theta:\\t{}'.format((pred_theta_min, pred_theta_max)))\n",
    "while bound_change > tol:\n",
    "    print('\\n')\n",
    "    new_pred_theta_min, new_pred_theta_max = get_implied_omega_theta(theta_ij, ij_error_terms)\n",
    "    print('Implied Omega_theta:\\t{}'.format((pred_theta_min, pred_theta_max)))\n",
    "    bound_change = np.abs(new_pred_theta_min - pred_theta_min) + np.abs(new_pred_theta_max - pred_theta_max)\n",
    "    print('Bound change: {}'.format(bound_change))\n",
    "    pred_theta_min = new_pred_theta_min\n",
    "    pred_theta_max = new_pred_theta_max\n",
    "    new_ij_error_terms = get_ij_error_bounds(pred_theta_min, pred_theta_max, x)\n",
    "\n",
    "    print('Results for new bounds:')\n",
    "    bounds_ok = check_error_bound(theta_ij, theta_cv, new_ij_error_terms)\n",
    "    if not bounds_ok:\n",
    "        print('################\\nBounds not ok -- terminating.')\n",
    "        bound_change = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
